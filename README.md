# ğŸ¤– AI Search Agent

**Intelligent Research Assistant with Multi-Tool Integration**

An advanced AI-powered search and research agent that leverages multiple tools including web search, Wikipedia lookup, and file operations to provide comprehensive research capabilities with automatic output saving and structured responses.

[![Python](https://img.shields.io/badge/Python-3.8+-3776ab?style=for-the-badge&logo=python&logoColor=white)](https://www.python.org/)
[![LangChain](https://img.shields.io/badge/LangChain-0.3.0-1c3c3c?style=for-the-badge&logo=langchain&logoColor=white)](https://langchain.com/)
[![OpenAI](https://img.shields.io/badge/OpenAI-GPT--4o-412991?style=for-the-badge&logo=openai&logoColor=white)](https://openai.com/)
[![Pydantic](https://img.shields.io/badge/Pydantic-2.11+-e92063?style=for-the-badge&logo=pydantic&logoColor=white)](https://pydantic.dev/)

## ğŸŒŸ Features

- ğŸ§  **Intelligent Research** - Multi-source research using web search and Wikipedia
- ğŸ” **Web Search Integration** - Real-time web search via DuckDuckGo
- ğŸ“š **Wikipedia Integration** - Comprehensive encyclopedia lookup
- ğŸ¤– **Tool-Calling Agent** - Advanced LangChain agent with structured outputs
- ğŸ“Š **Structured Responses** - Pydantic-based response formatting with validation

## ğŸ“· Screenshots

Example screenshots (stored in `imgs/`):

<p align="center">
    <img src="imgs/Capture d'Ã©cran 2025-11-23 171414.png" alt="Agent Screenshot 2" style="max-width:100%;height:auto" />
</p>

<p align="center">
    <img src="imgs/Capture d'Ã©cran 2025-11-23 171403.png" alt="Agent Screenshot 1" style="max-width:100%;height:auto" />
</p>

<p align="center">
    <img src="imgs/Capture d'Ã©cran 2025-11-23 182201.png" alt="Agent Screenshot 1" style="max-width:100%;height:auto" />
</p>

<p align="center">
    <img src="imgs/Capture d'Ã©cran 2025-11-23 182212.png" alt="Agent Screenshot 2" style="max-width:100%;height:auto" />
</p>

## ğŸ› ï¸ Tech Stack

**Backend:** Python 3.8+, LangChain, OpenAI GPT-4o  
**Search Tools:** DuckDuckGo Search, Wikipedia API  
**Data Processing:** Pydantic for structured outputs and validation  
**Agent Framework:** LangChain tool-calling agent architecture

## ğŸ—ï¸ Agent Architecture

The system uses a sophisticated tool-calling agent architecture built with LangChain:

### Core Components

- **ğŸ¤– LangChain Agent** - Tool-calling agent with GPT-4o integration
- **ğŸ” Search Tools** - Web search and Wikipedia lookup capabilities
- **ï¿½ Structured Output** - Pydantic models for consistent response formatting
- **ğŸ¯ Prompt Engineering** - Optimized prompts for research tasks

### Tool Integration

1. **ğŸŒ Web Search** - [`DuckDuckGoSearchRun`](tools.py) for real-time web information
2. **ğŸ“– Wikipedia** - [`WikipediaQueryRun`](tools.py) for encyclopedia content

### Data Flow

1. **ğŸ“ Query Input** - User provides research topic or question
2. **ğŸ¤– Agent Processing** - LangChain agent analyzes query and selects appropriate tools
3. **ï¿½ Information Gathering** - Tools execute searches and retrieve relevant data
4. **ğŸ“Š Response Generation** - GPT-4o synthesizes information into structured output
5. **ğŸ“‹ Structured Output** - Results returned in standardized ResearchResponse format

### Response Schema

```python
class ResearchResponse(BaseModel):
    topic: str              # Main research topic
    summary: str            # Comprehensive summary of findings
    sources: list[str]      # List of sources used
    tools_used: list[str]   # Tools utilized in research
```

## ğŸš€ Quick Start

### Prerequisites

- Python 3.8+
- OpenAI API key
- Git

### Environment Setup

1. **Clone the repository**

```bash
git clone https://github.com/Haythem532002/ai-search-agent.git
cd ai-search-agent
```

2. **Set up Python virtual environment**

```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. **Install dependencies**

```bash
pip install -r requirements.txt
```

4. **Configure environment variables**

Create a [`.env`](.env) file and add your OpenAI API key:

```env
OPENAI_API_KEY=your_openai_api_key_here
```

### Running the Application

**Start the research agent**

```bash
python main.py
```

The agent will automatically research the default query: "What is the capital of Tunisia"

### Customizing Queries

Modify the query in [`main.py`](main.py):

```python
raw_response = agent_executor.invoke(
    {"query": "Your research question here"})
```

### Example Usage

```python
# Example queries you can try:
queries = [
    "What are the latest developments in AI?",
    "Explain quantum computing basics",
    "What is the history of machine learning?",
    "How does blockchain technology work?"
]
```

## ğŸ“ Project Structure

```
AI-Search-Agent/
â”œâ”€â”€ app.py                         # Flask API server (primary backend)
â”œâ”€â”€ main.py                        # Legacy or alternate entrypoint (may be duplicate)
â”œâ”€â”€ tools.py                       # Tool definitions and implementations
â”œâ”€â”€ my-app/                        # Next.js frontend application
â”œâ”€â”€ imgs/                          # Example screenshots and images
â”œâ”€â”€ requirements.txt               # Python dependencies
â”œâ”€â”€ .env                           # Environment variables (API keys) - not committed
â”œâ”€â”€ .gitignore                     # Git ignore configuration
â”œâ”€â”€ README.md                      # Project documentation
â”œâ”€â”€ venv/                          # Python virtual environment (optional)
â””â”€â”€ .git/                          # Git repository metadata
```

Note: Prefer running `app.py` as the primary server (`python app.py`). If `main.py` exists it may be an older/duplicate server â€” run only one server to avoid port conflicts.

## ğŸ§ª Testing

### Run Basic Tests

```bash
# Test the agent with a simple query
python main.py

# Test individual tools
python -c "from tools import search_tool, wiki_tool, save_tool; print('Tools imported successfully')"

# Test OpenAI connection
python -c "from langchain_openai import ChatOpenAI; llm = ChatOpenAI(model='gpt-4o'); print('OpenAI connection OK')"
```

### Test Individual Components

```bash
# Test web search
python -c "from tools import search_tool; print(search_tool.run('Python programming'))"

# Test Wikipedia search
python -c "from tools import wiki_tool; print(wiki_tool.run('Artificial Intelligence'))"

# Test file saving
python -c "from tools import save_tool; print(save_tool.run('Test data'))"
```

### Custom Query Testing

```python
# Example test script
from main import agent_executor

test_queries = [
    "What is machine learning?",
    "History of the internet",
    "Climate change effects"
]

for query in test_queries:
    response = agent_executor.invoke({"query": query})
    print(f"Query: {query}")
    print(f"Response: {response}")
    print("-" * 50)
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Install development dependencies (`pip install -r requirements.txt`)
4. Make your changes with proper tests
5. Commit your changes (`git commit -m 'Add AmazingFeature'`)
6. Push to the branch (`git push origin feature/AmazingFeature`)
7. Open a Pull Request

### Development Guidelines

- Follow PEP 8 for Python code
- Use type hints where appropriate
- Write docstrings for functions and classes
- Test new features before submitting
- Update documentation for new functionality
- Use conventional commits for clear history

### Adding New Tools

To add a new tool to the agent:

1. Create the tool in [`tools.py`](tools.py):

```python
def your_new_tool(query: str) -> str:
    # Your tool implementation
    return result

new_tool = Tool(
    name="YourTool",
    func=your_new_tool,
    description="Description of what your tool does"
)
```

2. Add it to the tools list in [`main.py`](main.py):

```python
tools = [search_tool, wiki_tool, save_tool, new_tool]
```

## ğŸ“Š Performance & Monitoring

- **âš¡ Response Times**: Typical query response under 10-15 seconds
- **ğŸ¯ Accuracy**: High-quality responses with multi-source validation
- **ğŸ’¾ Storage**: Automatic research output persistence
- **ğŸ” Search Quality**: Dual-source information gathering (web + Wikipedia)
- **ğŸ“ Output Format**: Structured, validated responses with Pydantic

## ğŸ”’ Security & Best Practices

- **ï¿½ API Key Management**: Store OpenAI API key in `.env` file
- **ğŸ“ File Security**: Research outputs saved locally with timestamps
- **ğŸ›¡ï¸ Input Validation**: Pydantic models ensure data integrity
- **ğŸš« Rate Limiting**: Be mindful of OpenAI API usage limits
- **ğŸ” Search Safety**: DuckDuckGo provides safe web search results

## ğŸ“ˆ Future Enhancements

- ğŸ“„ **PDF Processing** - Add document ingestion capabilities
- ğŸ—„ï¸ **Database Integration** - Store research results in database
- ğŸŒ **Web Interface** - Add Flask/FastAPI web frontend
- ğŸ“Š **Analytics Dashboard** - Track research patterns and topics
- ğŸ”„ **Batch Processing** - Process multiple queries simultaneously
- ğŸ¯ **Source Ranking** - Implement source credibility scoring

## ğŸ“„ License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **ğŸ¦œ LangChain** for the excellent agent framework and tool integration
- **ğŸ¤– OpenAI** for providing the powerful GPT-4o language model
- **ğŸ” DuckDuckGo** for privacy-focused web search capabilities
- **ğŸ“š Wikipedia** for comprehensive encyclopedia content
- **ï¿½ Pydantic** for robust data validation and parsing

---

**Built with â¤ï¸ using Modern AI & Agent Architecture**
